{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb97c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39f33b",
   "metadata": {},
   "source": [
    "# 5.2 連鎖律\n",
    "- 合成関数の微分の性質\n",
    "- 高速に勾配を計算する誤差逆伝播法に応用する\n",
    "- ニューラルネット全体の関数を，各ノードの局所的な関数とその先の様々な関数の合成関数と考えて応用\n",
    "\n",
    "$$\n",
    "z = f(t) \\\\\n",
    "t = g(x, y)\n",
    "$$\n",
    "とすると，次のように合成関数の微分を求めることができる\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial t} \\frac{\\partial t}{\\partial x}\n",
    "$$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153ed17",
   "metadata": {},
   "source": [
    "### 単純な乗算レイヤ，加算レイヤ\n",
    "\n",
    "- 単純な乗算レイヤの例．\n",
    "- 様々な複雑な演算を含む損失関数を $ L(z) $ とする．\n",
    "- その内，一つの乗算ノードで $ z = xy $ という演算が行われるとする．\n",
    "\n",
    "このとき，次のように勾配を求めることができる\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\frac{\\partial z}{\\partial x} = \\frac{\\partial L}{\\partial z} y \\\\　\\\\\n",
    "\\frac{\\partial L}{\\partial y} = \\frac{\\partial L}{\\partial z} \\frac{\\partial z}{\\partial y} = \\frac{\\partial L}{\\partial z} x\n",
    "$$\n",
    "- $ \\frac{\\partial L}{\\partial z} $ は乗算ノードの出力 $ z $ での $ L $ の偏微分．\n",
    "- $ x, y $ を勾配計算に用いるため，順伝播の入力を保持しておく必要がある．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20efe8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363e8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x + y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout\n",
    "        dy = dout\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7b7b7",
   "metadata": {},
   "source": [
    "# 5.5 活性化関数レイヤ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0321e",
   "metadata": {},
   "source": [
    "### ReLUレイヤ\n",
    "#### ReLU\n",
    "$$\n",
    "y = \n",
    "\\begin{cases}\n",
    "    x \\quad (x \\gt 0) \\\\\n",
    "    0 \\quad (x \\leq 0)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### ReLUの偏微分\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x} = \n",
    "\\begin{cases}\n",
    "    1 \\quad (x \\gt 0) \\\\\n",
    "    0 \\quad (x \\leq 0)\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888fed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 入力が 0 以下のインデックスを保持し，その値は0とする\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # 順伝播の入力が 0 以下であったインデックスの値は 0 ，そのほかはそのまま逆伝播\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7183a0",
   "metadata": {},
   "source": [
    "### Sigmoidレイヤ\n",
    "#### Sigmoid\n",
    "$$\n",
    "y = \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "#### Sigmoidの偏微分導出\n",
    "$$\n",
    "t = 1 + \\exp(-x)\n",
    "$$\n",
    "\n",
    "とおくと，\n",
    "$$\n",
    "y = \\frac{1}{1 + \\exp(-x)} = \\frac{1}{t} = t^{-1}\n",
    "$$\n",
    "\n",
    "また，\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial y}{\\partial t} &= -t^{-2} = -(1 + \\exp(-x))^{-2}\\\\\n",
    "\\frac{\\partial t}{\\partial x} &= -\\exp(-x)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "であるから，\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial y}{\\partial x} &= \\frac{\\partial y}{\\partial t} \\frac{\\partial t}{\\partial x} \\\\ \\\\\n",
    "&= \\frac{\\exp(-x)}{\\{1 + \\exp(-x)\\}^{2}} \\\\ \\\\\n",
    "&= \\frac{\\exp(-x)}{1 + \\exp(-x)} \\frac{1}{1 + \\exp(-x)} \\\\ \\\\\n",
    "&= \\left(\\frac{1 + \\exp(-x)}{1 + \\exp(-x)} - \\frac{1}{1 + \\exp(-x)} \\right) \\frac{1}{1 + \\exp(-x)} \\\\ \\\\\n",
    "&= (1 - y) y\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b64cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # 逆伝播の入力に，Sigmoidの偏微分をかける\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe0a33",
   "metadata": {},
   "source": [
    "# 5.6 Affine / Softmaxレイヤ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81966205",
   "metadata": {},
   "source": [
    "### Affine変換\n",
    "$$\n",
    "\\boldsymbol{y} = \\boldsymbol{x} \\cdot W + \\boldsymbol{b}\n",
    "$$\n",
    "\n",
    "- $\\boldsymbol{y}, \\ \\boldsymbol{x}, \\ \\boldsymbol{b}$ はベクトル，$W$ は行列\n",
    "- 順伝播における，入力 $ \\boldsymbol{x} $，重み $ W $，バイアス $ \\boldsymbol{b} $ を表す\n",
    "- 損失関数 $ L(Y) (\\in \\boldsymbol{R}) $ の変数と考える\n",
    "\n",
    "***\n",
    "#### Affineレイヤの逆伝播\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{x}} = \\frac{\\partial L}{\\partial \\boldsymbol{y}} W^T \\\\ \\\\\n",
    "\\frac{\\partial L}{\\partial W} = \\boldsymbol{x}^T \\frac{\\partial L}{\\partial \\boldsymbol{y}} \\\\ \\\\\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "#### 導出\n",
    "- 第 $(l-1)$ 層から第 $l$ 層への変換を考える\n",
    "- 以下のように定義\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\boldsymbol{y} &= \\left( y_1, y_2, \\cdots, y_j, \\cdots, y_m \\right)\n",
    "\\\\ \\\\\n",
    "\\boldsymbol{x} &= \\left( x_1, x_2, \\cdots, x_k, \\cdots, x_n \\right)\n",
    "\\\\ \\\\\n",
    "W &= \\begin{pmatrix}\n",
    "w_{11} & w_{21} & \\cdots & w_{m1} \\\\\n",
    "w_{12} & w_{22} & \\cdots & w_{m2} \\\\\n",
    "\\vdots & \\vdots & w_{jk} & \\vdots \\\\\n",
    "w_{1n} & w_{2n} & \\cdots & w_{mn}\n",
    "\\end{pmatrix}\n",
    "\\\\ \\\\\n",
    "\\boldsymbol{b} &= \\left( b_1, b_2, \\cdots, b_j, \\cdots, b_m \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "- $n$: $(l-1)$ 層のノード数\n",
    "- $m$: $l$ 層のノード数\n",
    "- $\\boldsymbol{y}$: Affine変換後の $l$ 層への入力．\n",
    "- $\\boldsymbol{x}$: $(l-1)$ 層からの出力．\n",
    "- $W$: 重み．$w_{jk}$ は $(l-1)$ 層 $k$ 番目のノードから $l$ 層 $j$ 番目のノードへの重み．\n",
    "- $\\boldsymbol{b}$: バイアス．\n",
    "\n",
    "***\n",
    "\n",
    "Affine変換を成分表示\n",
    "\n",
    "$$\\boldsymbol{y} = \\left( x_1, x_2, \\cdots, x_k, \\cdots, x_n \\right)\n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{21} & \\cdots & w_{m1} \\\\\n",
    "w_{12} & w_{22} & \\cdots & w_{m2} \\\\\n",
    "\\vdots & \\vdots & w_{jk} & \\vdots \\\\\n",
    "w_{1n} & w_{2n} & \\cdots & w_{mn}\n",
    "\\end{pmatrix}\n",
    "+ \\left( b_1, b_2, \\cdots, b_j, \\cdots, b_m \\right)\n",
    "$$\n",
    "\n",
    "$\\boldsymbol{y}$ の成分 $y_j$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_j \n",
    "&= x_1 w_{j1} + x_2 w_{j2} + \\cdots  + x_n w_{jn} + b_j \\\\ \\\\\n",
    "&= \\Sigma_{k=1}^{n} x_k w_{jk} + b_j\n",
    "\\end{align}\n",
    "$$\n",
    "- $y_j$ は $x_k, \\ w_{jk}, \\ b_j, (k = 1, 2, \\cdots, n)$ の関数\n",
    "- $W, \\ \\boldsymbol{b}$ の $j$ 列目以外の成分は関係ない\n",
    "\n",
    "\n",
    "$\\boldsymbol{y}$ の成分 $y_j$ の偏微分\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial y_j}{\\partial x_k} \n",
    "&= w_{jk}\n",
    "\\\\ \\\\\n",
    "\\frac{\\partial y_j}{\\partial w_{jk}} \n",
    "&= x_k\n",
    "\\\\ \\\\\n",
    "\\frac{\\partial y_j}{\\partial b_j} \n",
    "&= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "損失関数の $L$ の $\\boldsymbol{x}$ による微分\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial x_k}\n",
    "&= \\frac{\\partial L}{\\partial y_1} \\frac{\\partial y_1}{\\partial x_k} + \\frac{\\partial L}{\\partial y_2} \\frac{\\partial y_2}{\\partial x_k} + \\cdots + \\frac{\\partial L}{\\partial y_m} \\frac{\\partial y_m}{\\partial x_k}\n",
    "\\\\ \\\\\n",
    "&= \\left( \\frac{\\partial L}{\\partial y_1}, \\frac{\\partial L}{\\partial y_2}, \\cdots, \\frac{\\partial L}{\\partial y_m} \\right)\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "\\frac{\\partial y_1}{\\partial x_k} \\\\\n",
    "\\frac{\\partial y_2}{\\partial x_k} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial y_m}{\\partial x_k}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\\\ \\\\\n",
    "&= \\frac{\\partial L}{\\partial \\boldsymbol{y}}\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "w_{1k}\\\\\n",
    "w_{2k} \\\\\n",
    "\\vdots \\\\\n",
    "w_{mk}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$k = 1, 2, \\cdots, n$ をまとめてベクトルにする\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{x}}\n",
    "&= \\left(\n",
    "\\frac{\\partial L}{\\partial x_1}, \\frac{\\partial L}{\\partial x_2}, \\cdots, \\frac{\\partial L}{\\partial x_n}\n",
    "\\right)\n",
    "\\\\ \\\\\n",
    "&= \\frac{\\partial L}{\\partial \\boldsymbol{y}}\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "w_{11} & w_{12} & \\cdots & w_{1n} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2n} \\\\\n",
    "\\vdots & \\vdots & & \\vdots \\\\\n",
    "w_{m1} & w_{m2} & \\cdots & w_{mn}\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\\\ \\\\\n",
    "&= \\frac{\\partial L}{\\partial \\boldsymbol{y}} W^T\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "損失関数の $L$ の $W$ による微分\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w_{jk}}\n",
    "&= \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial w_{jk}}\n",
    "\\\\ \\\\\n",
    "&= \\frac{\\partial L}{\\partial y_j} x_k\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$ j = 1, 2, \\cdots, m, k = 1, 2, \\cdots, n $ をまとめて行列にする\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial W}\n",
    "&= \\begin{pmatrix}\n",
    "\\frac{\\partial L}{\\partial w_{11}} & \\frac{\\partial L}{\\partial w_{21}} & \\cdots &\\frac{\\partial L}{\\partial w_{m1}} \\\\\n",
    "\\frac{\\partial L}{\\partial w_{12}} & \\frac{\\partial L}{\\partial w_{22}} & \\cdots &\\frac{\\partial L}{\\partial w_{m2}} \\\\\n",
    "\\vdots & \\vdots & & \\vdots \\\\\n",
    "\\frac{\\partial L}{\\partial w_{1n}} & \\frac{\\partial L}{\\partial w_{2n}} & \\cdots &\\frac{\\partial L}{\\partial w_{mn}}\n",
    "\\end{pmatrix}\n",
    "\\\\ \\\\\n",
    "&= \\begin{pmatrix}\n",
    "\\frac{\\partial L}{\\partial y_1} x_1 & \\frac{\\partial L}{\\partial y_2} x_1 & \\cdots &\\frac{\\partial L}{\\partial y_m} x_1 \\\\\n",
    "\\frac{\\partial L}{\\partial y_1} x_2 & \\frac{\\partial L}{\\partial y_2} x_2 & \\cdots &\\frac{\\partial L}{\\partial y_m} x_2 \\\\\n",
    "\\vdots & \\vdots & & \\vdots \\\\\n",
    "\\frac{\\partial L}{\\partial y_1} x_n & \\frac{\\partial L}{\\partial y_2} x_n & \\cdots &\\frac{\\partial L}{\\partial y_m} x_n \\\\\n",
    "\\end{pmatrix}\n",
    "\\\\ \\\\\n",
    "&= \\left( \\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{array} \\right)\n",
    "\\left( \\frac{\\partial L}{\\partial y_1}, \\frac{\\partial L}{\\partial y_2}, \\cdots, \\frac{\\partial L}{\\partial y_m} \\right)\n",
    "\\\\ \\\\\n",
    "&= \\boldsymbol{x}^T \\frac{\\partial L}{\\partial \\boldsymbol{y}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "補足\n",
    "\n",
    "$\\boldsymbol{v}_j = \\left( w_{j1}, w_{j2}, \\cdots, w_{jn} \\right)^T$ とおくと\n",
    "$W = \\left( \\boldsymbol{v}_1, \\boldsymbol{v}_2, \\cdots, \\boldsymbol{v}_m \\right)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial W}\n",
    "&= \\left( \\frac{\\partial L}{\\partial \\boldsymbol{v}_1}, \\frac{\\partial L}{\\partial \\boldsymbol{v}_2}, \\cdots, \\frac{\\partial L}{\\partial \\boldsymbol{v}_m} \\right)\n",
    "\\\\ \\\\\n",
    "&= \\left( \\frac{\\partial L}{\\partial \\boldsymbol{y}_1} \\frac{\\partial \\boldsymbol{y}_1}{\\partial \\boldsymbol{v}_1}, \\frac{\\partial L}{\\partial \\boldsymbol{y}_2} \\frac{\\partial \\boldsymbol{y}_2}{\\partial \\boldsymbol{v}_2}, \\cdots, \\frac{\\partial L}{\\partial \\boldsymbol{y}_m} \\frac{\\partial \\boldsymbol{y}_m}{\\partial \\boldsymbol{v}_m} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d6df1",
   "metadata": {},
   "source": [
    "#### バッチ対応Affineレイヤの実装\n",
    "- 重み $W$ と，バイアス $\\boldsymbol{b}$ を渡してインスタンスを生成\n",
    "- 入力 $\\boldsymbol{x}$ を渡して順伝播\n",
    "- $\\frac{\\partial L}{\\partial \\boldsymbol{y}}$ を渡して逆伝播\n",
    "- $\\frac{\\partial L}{\\partial \\boldsymbol{b}}$ はaxis=0で総和を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c529f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3f48f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29013ff5",
   "metadata": {},
   "source": [
    "#### Softmax-with-Lossレイヤ\n",
    "- 10種の手書き文字認識を例にとる\n",
    "- Softmaxレイヤへの入力は10個\n",
    "- Softmaxレイヤは入力された値を正規化して出力する\n",
    "- ここでは損失関数の交差エントロピー誤差を含めたレイヤを考える\n",
    "\n",
    "***\n",
    "\n",
    "#### Softmax関数\n",
    "$$\n",
    "y_k = \\frac{\\exp(a_k)}{\\Sigma_{i=1}^n \\exp(a_i)}\n",
    "$$\n",
    "- $\\boldsymbol{a} = (a_1, a_2, \\cdots, a_n)$: 前レイヤからの入力\n",
    "- $\\boldsymbol{y} = (y_1, y_2, \\cdots, y_n)$: Softmax関数の出力．$\\Sigma_{i=1}^{n} y_i = 1$\n",
    "\n",
    "#### Cross Entropy Error\n",
    "$$\n",
    "L = - \\Sigma_{k} t_k \\log y_k\n",
    "$$\n",
    "- $\\boldsymbol{t} = (t_1, t_2, \\cdots, t_n)$: 教師ラベル．上記の式ではone-hot表現．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29a90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
